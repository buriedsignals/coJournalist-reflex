================================================================================
CO-JOURNALIST DATABASE SCHEMA
================================================================================
Project: cojournalist
Project ID: eifgqlcfbmjcrvzomdtn
Database: PostgreSQL 17.6.1.032
Region: eu-west-1
Created: 2025-11-01

================================================================================
CUSTOM TYPES
================================================================================

1. regularity_type (ENUM)
   - weekly
   - monthly

2. scraper_status (ENUM)
   - draft
   - active
   - paused
   - error
   - completed

================================================================================
TABLE: users
================================================================================
Description: Stores user information linked to Clerk authentication

Columns:
  - id                    UUID          PRIMARY KEY, DEFAULT uuid_generate_v4()
  - clerk_id              VARCHAR(255)  UNIQUE, NOT NULL
  - timezone              VARCHAR(100)  NOT NULL, DEFAULT 'UTC'
  - credits_remaining     INTEGER       NOT NULL, DEFAULT 0, CHECK >= 0
  - created_at            TIMESTAMPTZ   NOT NULL, DEFAULT NOW()
  - updated_at            TIMESTAMPTZ   NOT NULL, DEFAULT NOW()

Indexes:
  - idx_users_clerk_id ON (clerk_id)

Constraints:
  - PRIMARY KEY: id
  - UNIQUE: clerk_id
  - CHECK: credits_remaining >= 0

Row Level Security: ENABLED (policies to be added with Clerk integration)

Triggers:
  - trg_users_updated_at: Auto-updates updated_at on UPDATE

Relationships:
  - Referenced by: scheduled_scrapers.user_id

================================================================================
TABLE: scheduled_scrapers
================================================================================
Description: Stores scheduled scraper configurations for each user

Columns:
  - id                    UUID                PRIMARY KEY, DEFAULT uuid_generate_v4()
  - user_id               UUID                NOT NULL, REFERENCES users(id) ON DELETE CASCADE
  - name                  VARCHAR(255)        NOT NULL
  - monitoring            BOOLEAN             NOT NULL, DEFAULT FALSE
                                              (When TRUE, scraper is active and will execute on schedule)
  - regularity            regularity_type     NOT NULL
  - day_number            SMALLINT            NOT NULL
                                              (1-7 for weekly: 1=Monday, 7=Sunday; 1-31 for monthly)
  - time_utc              TIME                NOT NULL
  - timezone              VARCHAR(100)        NOT NULL, DEFAULT 'UTC'
  - next_execution        TIMESTAMPTZ         NULLABLE
                                              (Next scheduled execution time, managed by AWS script)
  - last_execution        TIMESTAMPTZ         NULLABLE
  - scraper_service       VARCHAR(100)        NOT NULL (e.g., 'Firecrawl', 'Oxylabs', 'Apify')
  - prompt_summary        TEXT                NOT NULL
  - criteria              TEXT                NOT NULL
  - status                scraper_status      NOT NULL, DEFAULT 'draft'
  - created_at            TIMESTAMPTZ         NOT NULL, DEFAULT NOW()
  - updated_at            TIMESTAMPTZ         NOT NULL, DEFAULT NOW()

Indexes:
  - idx_scheduled_scrapers_user_id ON (user_id)
  - idx_scheduled_scrapers_next_execution ON (next_execution) WHERE monitoring = TRUE
  - idx_scheduled_scrapers_monitoring ON (monitoring)

Constraints:
  - PRIMARY KEY: id
  - FOREIGN KEY: user_id REFERENCES users(id) ON DELETE CASCADE
  - CHECK valid_day_number:
      (regularity = 'weekly' AND day_number BETWEEN 1 AND 7) OR
      (regularity = 'monthly' AND day_number BETWEEN 1 AND 31)

Row Level Security: ENABLED (policies to be added with Clerk integration)

Triggers:
  - trg_update_scraper_status: Auto-updates status based on monitoring flag changes
    * monitoring FALSE → TRUE: status = 'active'
    * monitoring TRUE → FALSE: status = 'paused'
    * Also auto-updates updated_at timestamp

Relationships:
  - References: users(id)
  - Referenced by: scraper_executions.scraper_id

================================================================================
TABLE: scraper_executions
================================================================================
Description: Logs execution history and results for each scraper run

Columns:
  - id                    UUID          PRIMARY KEY, DEFAULT uuid_generate_v4()
  - scraper_id            UUID          NOT NULL, REFERENCES scheduled_scrapers(id) ON DELETE CASCADE
  - executed_at           TIMESTAMPTZ   NOT NULL, DEFAULT NOW()
  - success               BOOLEAN       NOT NULL
  - status_code           INTEGER       NULLABLE
  - error_message         TEXT          NULLABLE
  - items_found           INTEGER       DEFAULT 0
  - credits_used          INTEGER       DEFAULT 0
  - execution_time_ms     INTEGER       NULLABLE
  - result_summary        JSONB         NULLABLE (flexible storage for results metadata)
  - created_at            TIMESTAMPTZ   NOT NULL, DEFAULT NOW()

Indexes:
  - idx_scraper_executions_scraper_id ON (scraper_id)
  - idx_scraper_executions_executed_at ON (executed_at DESC)

Constraints:
  - PRIMARY KEY: id
  - FOREIGN KEY: scraper_id REFERENCES scheduled_scrapers(id) ON DELETE CASCADE

Row Level Security: ENABLED (policies to be added with Clerk integration)

Triggers: None

Relationships:
  - References: scheduled_scrapers(id)

================================================================================
VIEW: scrapers_pending_execution
================================================================================
Description: Helper view for active scrapers ready to run
Security: SECURITY DEFINER (intentional - allows service role to query all users)

Query:
  SELECT
    s.*,
    u.credits_remaining,
    u.clerk_id
  FROM scheduled_scrapers s
  JOIN users u ON s.user_id = u.id
  WHERE s.monitoring = TRUE
    AND s.next_execution <= NOW()
    AND u.credits_remaining > 0
  ORDER BY s.next_execution ASC

Columns:
  - All columns from scheduled_scrapers
  - credits_remaining (from users)
  - clerk_id (from users)

Use Case: AWS script queries this view to get all scrapers ready for execution

================================================================================
FUNCTIONS
================================================================================

1. update_scraper_status()
   Returns: TRIGGER
   Description: Auto-updates status based on monitoring flag
   Logic:
     - monitoring FALSE → TRUE: status = 'active'
     - monitoring TRUE → FALSE: status = 'paused'
     - Always updates updated_at = NOW()

2. update_updated_at()
   Returns: TRIGGER
   Description: Auto-updates updated_at timestamp on users table

3. record_scraper_execution()
   Returns: UUID (execution_id)
   Parameters:
     - p_scraper_id          UUID      (required)
     - p_success             BOOLEAN   (required)
     - p_status_code         INTEGER   (optional)
     - p_error_message       TEXT      (optional)
     - p_items_found         INTEGER   (default: 0)
     - p_credits_used        INTEGER   (default: 1)
     - p_execution_time_ms   INTEGER   (optional)
     - p_result_summary      JSONB     (optional)

   Description: Records execution results and updates last execution time
   Logic:
     1. Inserts execution record into scraper_executions
     2. If successful, updates scheduled_scrapers.last_execution = NOW()
     3. Deducts credits from users.credits_remaining
     4. Returns the execution record ID

================================================================================
EXTENSIONS
================================================================================
- uuid-ossp (for UUID generation)

================================================================================
NEXT STEPS
================================================================================

1. Configure Clerk JWT Claims:
   - Add 'sub' claim for user ID
   - Add 'role: authenticated' claim

2. Add RLS Policies (after Clerk integration):

   -- Users table
   CREATE POLICY users_clerk_policy ON users
       FOR ALL USING (auth.jwt()->>'sub' = clerk_id);

   -- Scheduled scrapers table
   CREATE POLICY scheduled_scrapers_policy ON scheduled_scrapers
       FOR ALL USING (
           user_id IN (
               SELECT id FROM users WHERE clerk_id = auth.jwt()->>'sub'
           )
       );

   -- Scraper executions table
   CREATE POLICY scraper_executions_policy ON scraper_executions
       FOR ALL USING (
           scraper_id IN (
               SELECT s.id FROM scheduled_scrapers s
               JOIN users u ON s.user_id = u.id
               WHERE u.clerk_id = auth.jwt()->>'sub'
           )
       );

3. Optional Security Hardening:
   - Add SET search_path = '' to functions
   - Review SECURITY DEFINER on scrapers_pending_execution view

================================================================================
ADVISOR NOTES
================================================================================

Expected Warnings:
  - RLS enabled but no policies (will be resolved after Clerk integration)
  - Unused indexes (normal for empty tables)
  - Function search_path mutable (optional security hardening)
  - SECURITY DEFINER view (intentional for service role access)

================================================================================
END OF SCHEMA DOCUMENTATION
================================================================================
